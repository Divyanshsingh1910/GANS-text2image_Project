{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "> This assignment as two parts Section A and B. The first part is the implementation of function required in applying the CNN layers and the next section will be around the use of built in function of Tensorflow"
      ],
      "metadata": {
        "id": "P3hDtc9rMxkR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "`Before moving ahead as we have reached the stage of applying CNNs. We are going to deal with large number of parameters and hence more computational power. So you will need to connect runtime of collab to GPU: https://www.youtube.com/watch?v=-9CLfrZISRw`"
      ],
      "metadata": {
        "id": "48fGpBzYOjt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **BOTH THE SECTION CAN BE SOLVED INDEPENDENTLY** BUT SECTION A has **3X** more weightage than SECTION B doesn't have any code to write."
      ],
      "metadata": {
        "id": "4mSFI4ExalwM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SECTION:A**"
      ],
      "metadata": {
        "id": "CjXMqW4cMrFg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "e8eFBZbMLxGM"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbWwF7vkLxGP"
      },
      "source": [
        "### Q1: Complete the following function corr2d(X, K), which implements the cross correlation operation for matrix X and kernel K, both are two dimensional numpy arrays (height x width). The function should return a 2 dimensional numpy array which is the result of cross correlation operation between X and K. \n",
        "\n",
        "- not giving channels right now : assume channels = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2rVZCrIDLxGT"
      },
      "outputs": [],
      "source": [
        "def corr2d(X: np.array, K: np.array) -> np.array:\n",
        "\n",
        "    # no padding for now and assume stride = 1\n",
        "    h_X,w_X = X.shape\n",
        "    h_K,w_K = K.shape\n",
        "    h_res=h_X - h_K + 1\n",
        "    w_res=w_X - w_K + 1\n",
        "\n",
        "    result=np.zeros((h_res,w_res))\n",
        "    for i in range(h_res):\n",
        "      for j in range(w_res):\n",
        "        result[i,j]=np.sum(X[i:i+h_K,j:j+w_K] * K)\n",
        "    return result\n",
        "       \n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FYF60FbvLxGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5cbeaec-fcbc-4561-c74e-b37d69ceeae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[19. 25.]\n",
            " [37. 43.]]\n"
          ]
        }
      ],
      "source": [
        "X = np.array([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]], dtype=np.float32)\n",
        "K = np.array([[0.0, 1.0], [2.0, 3.0]], dtype=np.float32)\n",
        "print(corr2d(X, K)) # example done in class, try to print this and check if you get the right answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLMP6bE3LxGf"
      },
      "source": [
        "### now try to make a new function corr2d_multiple_input_channels(X, K) : where each X and K have the same number of channels, both of them are now 3 dimensional numpy arrays, the output should be a 2 dimensional numpy array (output_h, output_w).\n",
        "\n",
        "- hint : Use the above corr2d function and read about np.stack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "glmBGALxLxGg"
      },
      "outputs": [],
      "source": [
        "def corr2d_multiple_input_channels(X: np.array, K: np.array) -> np.array: \n",
        "    # write a function for this task\n",
        "    channel=X.shape[0]\n",
        "    output_h=X.shape[1] - K.shape[1] + 1\n",
        "    output_w=X.shape[2] - K.shape[2] + 1\n",
        "    output=np.zeros((output_h,output_w))\n",
        "    X_stacked=np.stack(X,axis=0)\n",
        "    K_stacked=np.stack(K,axis=0)\n",
        "    for i in range(channel):\n",
        "        output += corr2d(X_stacked[i], K_stacked[i])\n",
        "\n",
        "    return output\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Iw3vxttBLxGg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b98256a6-30e7-4efa-9b3b-7b52bfeeaa01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new_X.shape = (3, 3, 3), new_K.shape = (3, 2, 2)\n",
            "[[119. 149.]\n",
            " [209. 239.]]\n"
          ]
        }
      ],
      "source": [
        "new_X = np.stack([X, X+1, X+2], axis=0) # stacking along a new dimension\n",
        "new_K = np.stack([K, K+1, K+2], axis=0) \n",
        "\n",
        "print(f\"new_X.shape = {new_X.shape}, new_K.shape = {new_K.shape}\")\n",
        "print(corr2d_multiple_input_channels(new_X, new_K))\n",
        "# calculate the output by hand and then check whether you get the same answer\n",
        "# answer should be a 2 dim np array : (output_height, output_width) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhXuwIj9LxGh"
      },
      "source": [
        "### Write another function corr2d_mutli_in_out(X, K): where X (3 dim np array), K (4 dim numpy array), 0th dimension of K represents the number of kernel/filters we are using. Perform the cross correlation operation for K on X and return the output : 3 dim numpy array whose shape should be (num_output_channels, output_height, output_width)\n",
        "\n",
        "- hint : use the above corr_2d_mutliple_input_channels(X, K) for each kernel in K and then stack them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "f3H-oe3xLxGi"
      },
      "outputs": [],
      "source": [
        "#for i in range(K.shape[0]):\n",
        " #print(K[i])\n",
        "\n",
        "def corr2d_multi_in_out(X: np.array, K: np.array) -> np.array:\n",
        "    # X -> (num_in_channels, n_h, n_w)\n",
        "    # K -> (num_out_channels, num_in_channels, k_h, k_w)\n",
        "    # output -> (num_out_channels, o_h,o_w)\n",
        "  \n",
        "    num_output_channels = K.shape[0]\n",
        "    o_h = X.shape[1] - K.shape[2] + 1\n",
        "    o_w = X.shape[2] - K.shape[3] + 1\n",
        "    output = np.zeros((num_output_channels, o_h, o_w))\n",
        "    for i in range(num_output_channels):\n",
        "     output[i] = corr2d_multiple_input_channels(X, K[i])\n",
        "    return output \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8KvPQ4eYLxGi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aa15026-6655-4763-e702-048066b097ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my_K.shape = (4, 3, 2, 2)\n",
            "[[[119. 149.]\n",
            "  [209. 239.]]\n",
            "\n",
            " [[155. 197.]\n",
            "  [281. 323.]]\n",
            "\n",
            " [[191. 245.]\n",
            "  [353. 407.]]\n",
            "\n",
            " [[227. 293.]\n",
            "  [425. 491.]]]\n"
          ]
        }
      ],
      "source": [
        "my_K = np.stack([new_K, new_K+1, new_K+2, new_K + 3], axis=0) \n",
        "print(f\"my_K.shape = {my_K.shape}\")\n",
        "\n",
        "print(corr2d_multi_in_out(new_X, my_K)) # cross check the calculation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGjUjrXQLxGj"
      },
      "source": [
        "### Q2: What is the computational and statistical benefits of stride larger than 1?? (not more than 20 word answer for each)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A greater stride minimizes the number of computations necessary in the convolutional layer, resulting in faster training and inference times"
      ],
      "metadata": {
        "id": "Z_AUUZgXMdaj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_dSJFchLxGj"
      },
      "source": [
        "### Q3: Now let's implement a model with just a single convolution layer, given X(input), Y(output) and K(kernel). Y is the output of the cross-correlation operation of K on X. You need to build a model to learn that kernel K.(try to print the kernel at each epoch)\n",
        "\n",
        "- hint : conv_layer(output_channels = 1, input_channels = 1, kerenl_size=(1, 2), bias=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uWAF0RPhLxGj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f753755f-28a2-49d3-cbd9-e3281b15fa71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1. 0. 0. 0. 0. 1. 1.]\n",
            " [1. 1. 0. 0. 0. 0. 1. 1.]\n",
            " [1. 1. 0. 0. 0. 0. 1. 1.]\n",
            " [1. 1. 0. 0. 0. 0. 1. 1.]\n",
            " [1. 1. 0. 0. 0. 0. 1. 1.]\n",
            " [1. 1. 0. 0. 0. 0. 1. 1.]]\n"
          ]
        }
      ],
      "source": [
        "X = np.ones((6, 8), dtype=np.float32)\n",
        "X[:, 2:6] = 0\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "pr0_V5lpLxGj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6452ecd-1b45-49a2-fdbb-8c1eab9faefe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.  1.  0.  0.  0. -1.  0.]\n",
            " [ 0.  1.  0.  0.  0. -1.  0.]\n",
            " [ 0.  1.  0.  0.  0. -1.  0.]\n",
            " [ 0.  1.  0.  0.  0. -1.  0.]\n",
            " [ 0.  1.  0.  0.  0. -1.  0.]\n",
            " [ 0.  1.  0.  0.  0. -1.  0.]]\n"
          ]
        }
      ],
      "source": [
        "K = np.array([[1.0, -1.0]], dtype=np.float32) # kernel, you need to learn this using a model\n",
        "Y = corr2d(X, K) \n",
        "print(Y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "4HSVk5foLxGk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "008f86b6-93b1-40ad-dcc2-b990e4ee646a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2855 Kernel:  1\n",
            "[[[[-0.07835685]]\n",
            "\n",
            "  [[ 0.696731  ]]]]\n",
            "1/1 [==============================] - 1s 546ms/step - loss: 0.2855\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2766 Kernel:  2\n",
            "[[[[-0.1065216]]\n",
            "\n",
            "  [[ 0.696731 ]]]]\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2766\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2700 Kernel:  3\n",
            "[[[[-0.13477063]]\n",
            "\n",
            "  [[ 0.7158927 ]]]]\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2700\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2654 Kernel:  4\n",
            "[[[[-0.16346958]]\n",
            "\n",
            "  [[ 0.73928404]]]]\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2654\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2597 Kernel:  5\n",
            "[[[[-0.19250865]]\n",
            "\n",
            "  [[ 0.7595598 ]]]]\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2597\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2553 Kernel:  6\n",
            "[[[[-0.22192214]]\n",
            "\n",
            "  [[ 0.7776803 ]]]]\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2553\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2507 Kernel:  7\n",
            "[[[[-0.25172785]]\n",
            "\n",
            "  [[ 0.7944442 ]]]]\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2507\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2460 Kernel:  8\n",
            "[[[[-0.28191698]]\n",
            "\n",
            "  [[ 0.8105851 ]]]]\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2460\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2416 Kernel:  9\n",
            "[[[[-0.31246114]]\n",
            "\n",
            "  [[ 0.826789  ]]]]\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2416\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2376 Kernel:  10\n",
            "[[[[-0.34331924]]\n",
            "\n",
            "  [[ 0.84366995]]]]\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2376\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2338 Kernel:  11\n",
            "[[[[-0.37444282]]\n",
            "\n",
            "  [[ 0.8617201 ]]]]\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2338\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2304 Kernel:  12\n",
            "[[[[-0.40578163]]\n",
            "\n",
            "  [[ 0.88126284]]]]\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2304\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2270 Kernel:  13\n",
            "[[[[-0.43729016]]\n",
            "\n",
            "  [[ 0.9024352 ]]]]\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2270\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2236 Kernel:  14\n",
            "[[[[-0.46893442]]\n",
            "\n",
            "  [[ 0.9252094 ]]]]\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2236\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2200 Kernel:  15\n",
            "[[[[-0.5006982]]\n",
            "\n",
            "  [[ 0.9494383]]]]\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2200\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2161 Kernel:  16\n",
            "[[[[-0.5325868]]\n",
            "\n",
            "  [[ 0.9748952]]]]\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2161\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2119 Kernel:  17\n",
            "[[[[-0.56462735]]\n",
            "\n",
            "  [[ 1.0012918 ]]]]\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2119\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2073 Kernel:  18\n",
            "[[[[-0.59686476]]\n",
            "\n",
            "  [[ 1.0282686 ]]]]\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2073\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2025 Kernel:  19\n",
            "[[[[-0.62935495]]\n",
            "\n",
            "  [[ 1.0553626 ]]]]\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2025\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1975 Kernel:  20\n",
            "[[[[-0.66215575]]\n",
            "\n",
            "  [[ 1.0819572 ]]]]\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1975\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1926 Kernel:  21\n",
            "[[[[-0.69531804]]\n",
            "\n",
            "  [[ 1.1072316 ]]]]\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1926\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1876 Kernel:  22\n",
            "[[[[-0.7288695]]\n",
            "\n",
            "  [[ 1.130237 ]]]]\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1876\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1827 Kernel:  23\n",
            "[[[[-0.7627062]]\n",
            "\n",
            "  [[ 1.1511837]]]]\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1827\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1779 Kernel:  24\n",
            "[[[[-0.7967226]]\n",
            "\n",
            "  [[ 1.1702605]]]]\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1779\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1731 Kernel:  25\n",
            "[[[[-0.83080757]]\n",
            "\n",
            "  [[ 1.1876374 ]]]]\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1731\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1686 Kernel:  26\n",
            "[[[[-0.8648404]]\n",
            "\n",
            "  [[ 1.203468 ]]]]\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1686\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1642 Kernel:  27\n",
            "[[[[-0.89868677]]\n",
            "\n",
            "  [[ 1.2178909 ]]]]\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1642\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1602 Kernel:  28\n",
            "[[[[-0.9321949]]\n",
            "\n",
            "  [[ 1.2310319]]]]\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1602\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1565 Kernel:  29\n",
            "[[[[-0.9651914]]\n",
            "\n",
            "  [[ 1.243005 ]]]]\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1565\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1532 Kernel:  30\n",
            "[[[[-0.9974782]]\n",
            "\n",
            "  [[ 1.2539139]]]]\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1532\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1503 Kernel:  31\n",
            "[[[[-1.02883  ]]\n",
            "\n",
            "  [[ 1.2638527]]]]\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1503\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1480 Kernel:  32\n",
            "[[[[-1.0589943]]\n",
            "\n",
            "  [[ 1.2729071]]]]\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1480\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1461 Kernel:  33\n",
            "[[[[-1.0876937]]\n",
            "\n",
            "  [[ 1.2811552]]]]\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1461\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1447 Kernel:  34\n",
            "[[[[-1.1146334]]\n",
            "\n",
            "  [[ 1.288668 ]]]]\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1447\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1438 Kernel:  35\n",
            "[[[[-1.1395134]]\n",
            "\n",
            "  [[ 1.2955104]]]]\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1438\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1433 Kernel:  36\n",
            "[[[[-1.1620454]]\n",
            "\n",
            "  [[ 1.3017415]]]]\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1433\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1431 Kernel:  37\n",
            "[[[[-1.1819746]]\n",
            "\n",
            "  [[ 1.3074152]]]]\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1431\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1433 Kernel:  38\n",
            "[[[[-1.1991019]]\n",
            "\n",
            "  [[ 1.3125807]]]]\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1433\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1436 Kernel:  39\n",
            "[[[[-1.2133019]]\n",
            "\n",
            "  [[ 1.3172829]]]]\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1436\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1438 Kernel:  40\n",
            "[[[[-1.22454  ]]\n",
            "\n",
            "  [[ 1.3215628]]]]\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1438\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1441 Kernel:  41\n",
            "[[[[-1.2328811]]\n",
            "\n",
            "  [[ 1.3254576]]]]\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1441\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1442 Kernel:  42\n",
            "[[[[-1.238487 ]]\n",
            "\n",
            "  [[ 1.3290015]]]]\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1442\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1442 Kernel:  43\n",
            "[[[[-1.2416052]]\n",
            "\n",
            "  [[ 1.3322257]]]]\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1442\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1440 Kernel:  44\n",
            "[[[[-1.2425518]]\n",
            "\n",
            "  [[ 1.3351586]]]]\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1440\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1438 Kernel:  45\n",
            "[[[[-1.2416922]]\n",
            "\n",
            "  [[ 1.337826 ]]]]\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1438\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1436 Kernel:  46\n",
            "[[[[-1.2394217]]\n",
            "\n",
            "  [[ 1.3402517]]]]\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1436\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1433 Kernel:  47\n",
            "[[[[-1.2361482]]\n",
            "\n",
            "  [[ 1.3424573]]]]\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1433\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1431 Kernel:  48\n",
            "[[[[-1.232275 ]]\n",
            "\n",
            "  [[ 1.3444624]]]]\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1431\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1430 Kernel:  49\n",
            "[[[[-1.2281858]]\n",
            "\n",
            "  [[ 1.346285 ]]]]\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1430\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1429 Kernel:  50\n",
            "[[[[-1.2242308]]\n",
            "\n",
            "  [[ 1.3479414]]]]\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1429\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb930ced600>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "\n",
        "X = X.reshape((1, 1, 6, 8)) # this will be the input to the model\n",
        "Y = Y.reshape((1, 1, 6, 7)) # this is the output, to be used while calculation loss\n",
        "lr = 3e-2                   # use this learning rate\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=1, kernel_size=(1, 2), input_shape=(  1, 6, 8,1), use_bias=False))\n",
        "\n",
        "class ValueatKernel(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch=50, logs=None):\n",
        "        weights = self.model.get_weights()\n",
        "        kernel = weights[0]\n",
        "        print(\" Kernel: \", 1+epoch)\n",
        "        print(kernel)\n",
        "learning_rate = 3e-2\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "              loss='mean_squared_error')\n",
        "model.add(tf.keras.layers.Conv2D(1, ( 1, 1), activation = 'relu'))\n",
        "model.fit(X, Y, epochs=50, callbacks=[ValueatKernel()])\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sWbsvXQLxGk"
      },
      "source": [
        "### Q4: Complete the following function max_pool2d(X, K) which performs maxpooling with kernel size K on X and returns and two dim numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Qjsv_v_LxGk"
      },
      "outputs": [],
      "source": [
        "def max_pool2d(X: np.array, K: tuple) -> np.array:\n",
        "    # write a function for this job\n",
        "    \n",
        " \n",
        "  output_height = X.shape[0] // K[0] +1\n",
        "  output_width = X.shape[1] // K[1] + 1\n",
        "  output = np.zeros((output_height, output_width))\n",
        "    \n",
        "  for i in range(output_height):\n",
        "        for j in range(output_width):\n",
        "            output[i, j] = np.max(X[i*K[0]:(i)*K[0]+K[0], j*K[1]:(j)*K[1] + K[1]])\n",
        "    \n",
        "  return output\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiLo_mjSLxGl"
      },
      "outputs": [],
      "source": [
        "X = np.array([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]], dtype=np.float32)\n",
        "\n",
        "max_pool2d(X,(2,2)) #check if the output matches with your calculation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-niSYY3LxGl"
      },
      "source": [
        "# **SECTION:B**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **JUST RUN THE CELLS AND VISUALIZE**( Nothing to code 🙂 )\n",
        "\n",
        "> Indented block\n",
        "\n"
      ],
      "metadata": {
        "id": "pfa0otIGY4vf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mI1blAXSLxGl"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the dataset\n",
        "(X_train,Y_train),(X_test,Y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X_train,Y_train,test_size=0.3)"
      ],
      "metadata": {
        "id": "hjSRQ2QuNf69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print shape of all 4 variables: X_train,Y_train,X_test, and Y_test\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)"
      ],
      "metadata": {
        "id": "fhl64KENQSuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets visualize the CIFAR-10 dataset\n",
        "\n",
        "import random\n",
        "figure = plt.figure(figsize=(6,6))\n",
        "\n",
        "for i in range(9):\n",
        "  index = random.randint(0,len(X_train)-1) # showing the index_th image\n",
        "  \n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.imshow(X_train[index])\n",
        "  plt.title(Y_train[index])\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "Oygw7B1fNm0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "So you can probably notice here that the images are 3D(coloured) but still \n",
        "not of great quality ( what can you expect from 32x32 image). Also there are\n",
        "certain other factors which makes the classification a bit tougher than the \n",
        "cases of 2D( the digit and the fashion data) you dealt before. We will try to\n",
        "understand the difficulties and find probable solution for them.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "mIY0GmLjSMvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "ATuu2w_SNuCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Lets first start with the CNN model discussed in the class for digit\n",
        " classification. Notice that I have changed the input shape for this usecase.\n",
        " Earlier it was (28,28,1) for the digit dataset.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "w1yCGBaMSz5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model initialization\n",
        "cnn_model = tf.keras.Sequential()\n",
        "\n",
        "# adding the 1st layer of CNN\n",
        "cnn_model.add(tf.keras.layers.Conv2D(26, (5,5), activation = 'relu', input_shape=(32,32,3)))\n",
        "\n",
        "# adding a maxpooling\n",
        "cnn_model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
        "\n",
        "#adding another CNN layer\n",
        "cnn_model.add(tf.keras.layers.Conv2D(16, (5,5), activation = 'relu'))\n",
        "\n",
        "# adding another maxpooling layer\n",
        "cnn_model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
        "\n",
        "#flattening the layer\n",
        "cnn_model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# 20 x 20 x 16\n",
        "#dense layer\n",
        "cnn_model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "\n",
        "# final layer \n",
        "cnn_model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "UNr0XFiKNpnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "tWoQIGv7N0tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Explain what is Adam optimizer below in atleast 250 words.[ read on web and explain ]\n",
        "\n",
        "Answer:Adaptive Moment Estimation(adam) is the most popular,powerful and widely used optimizer for updating the parameters of neural network training.\n",
        "It is an algorithm for optimization technigue for gradient descent.This is very efficient  when working with large problems involving a lot of data or parameters.It\n",
        "requires less memory as compare to other optimization technique.It is a combo of the 'gradient descent with momentum' algorithm and the 'RMSP' algorithm.\n",
        "Since weight updation in gradient descent is not straight forward therefore lot of time is wasted to reach local minima so to reduce the time taken to train a model we use optimization\n",
        "and the best technique algorithm is adam.\n",
        "The algorithm computes individual adaptive learning rates for each parameter by estimating the mean and variance of the gradients.It maintains a dynamic mean and gradient square very \n",
        "steeply with decay rates to adjust learning rates accordingly.By using adam we can scale the learning rate adaptively for each parameter based on previous gradients.This adaptive scaling\n",
        "allows faster convergence,it also helps mitigate the issues of vanishing or exploding gradients.\n",
        "The algorithm of adam involves three steps during each iteration:\n",
        "1.Computation of gradient:refers to calculation of partial derivatives of a loss function with respect to the parameters of a neural network.It rrepresent the steepest descent or ascent\n",
        "in the parameter space .Back propogation is very efficient way of computing gradient.\n",
        "2.updation of moments:adam maintains the moving mean of gradient and squared gradient.These are updated based on the current gradient and the decay rates for the first and second moments,\n",
        " respectively.\n",
        "3.Updating the parameters:The parameters of the network are updated using adapting rates calculated from mean and variance of gradients.The update step involves scaling the gradients by\n",
        " the learning rate and applying them to the parameters.\n",
        "\n",
        " https://www.geeksforgeeks.org/adam-optimizer-in-tensorflow/\n",
        " https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "yau4nndbTU4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Make sure that you are connected to GPU runtime other wise the training in next cell is going to take a long time**"
      ],
      "metadata": {
        "id": "x5rLNjUlPKrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = cnn_model.fit(X_train, Y_train, epochs=10, validation_split=0.2)"
      ],
      "metadata": {
        "id": "9RPCnjevN3W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "Write about validation accuracy in 100 words.\n",
        "\n",
        "Answer: Validation accuracy is measure of how well the trained model work on unseen dataset whichb are not seen during training.\n",
        "This is essential way to check on the model's generalization capability and effectiveness in making accurate predictions on new \n",
        "unseen datas.In the above data ,validation accuracy is around range of 0.09-0.11.In the range of 0.09 to 0.1, the validation accuracy\n",
        "suggests that the model is performing poorly on the validation data and is making incorrect prediction in the majority of cases. It means \n",
        "that the model's predictions align with the correct labels for only around 9% to 11% of the examples in the validation dataset.This suggest \n",
        "that it is in struggle for model to improve its perfomance.\n",
        "\n",
        "https://stats.stackexchange.com/questions/401696/validation-accuracy-vs-testing-accuracy\n",
        "https://www.kaggle.com/questions-and-answers/56171\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "XMqr0nejTrrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'],label=\"Train accuracy\")\n",
        "plt.plot(history.history['val_accuracy'], label = \"Validation accuracy\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "2AkZcRmbN6SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "What do you think is happening? Is the model training or not?\n",
        " You can see that both the training and validation accuracy are\n",
        " just roaming around 0.1. \n",
        " One reason for this can be our model architecture. We had 26 filters\n",
        " in our first layer and 16 filters in our next layer. This funnel down approach\n",
        " works for dense layers but for Conv layers( which are good at feature extraction)\n",
        " we want them to extract more and more features.\n",
        "\n",
        " So lets change that to funne up --> 16 and 32 in the layers respectively\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "xEQ0UpBDTN_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model initialization\n",
        "cnn_model = tf.keras.Sequential()\n",
        "\n",
        "\"\"\"adding the 1st layer of CNN(Changed)\"\"\"\n",
        "cnn_model.add(tf.keras.layers.Conv2D(16, (5,5), activation = 'relu', input_shape=(32,32,3)))\n",
        "\n",
        "# adding a maxpooling\n",
        "cnn_model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
        "\n",
        "\"\"\"adding the 2nd layer of CNN(Changed)\"\"\"\n",
        "cnn_model.add(tf.keras.layers.Conv2D(32, (5,5), activation = 'relu'))\n",
        "\n",
        "# adding another maxpooling layer\n",
        "cnn_model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
        "\n",
        "#flattening the layer\n",
        "cnn_model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# 20 x 20 x 16\n",
        "#dense layer\n",
        "cnn_model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "\n",
        "# final layer \n",
        "cnn_model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "6HcpdtBuN8_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "tFXQBRGPRjK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = cnn_model.fit(X_train, Y_train, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "id": "WzC0iaowRmpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'],label=\"Train accuracy\")\n",
        "plt.plot(history.history['val_accuracy'], label = \"Validation accuracy\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "HdnpcDQoRrGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Did our model improved??\n",
        "# Yes before this validation and train acuracy were less as compare to current,where validation accuracy goes upto 0.45 but now it is upto 0.5444.\n",
        "\n",
        "Are we done with the job?\n",
        "#Not yet as model is overfitting after a particular epoch value.\n",
        "\n",
        "What is happening after 5( roughly ) epochs? Why is there a gap between\n",
        "training and validation accuracy?\n",
        "Our training accuracy reached to 0.73( and still increasing ) but \n",
        "the validation accuracy seems to stagnate at 0.52.\n",
        "\n",
        "\n",
        "##After epochs roughly 5,difference between validation and training accuracy is increasing as epoch value increases which implies overfitting of model.\n",
        "The increasing difference between validation accuracy and training accuracy as the number of epochs increases is a common phenomenon known as overfitting. \n",
        "This occurs because model becomes too specialized in learning from the training data and performs poorly on new, unseen data.\n",
        "Is our model overfitting on the training data so much that it can't work well \n",
        "on unseen data.\n",
        "#Yes,it is as it have higher accuracy for training dataset but not so for validation dataset.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "MX4njN_DUwlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "How are we gonna tackel this problem?\n",
        "We can use regularization techniques as mentioned in one question.\n",
        "Well, we will see that in next part of this assignment.\n",
        "Till then lets learn about about overfitting.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "3l82eHENWI-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Well using Chatgpt to answer these question is something which everyone can think of right?? To create a difference write answer in your own terms after reading from web or reading the answer of Chatgpt.**\n",
        "### **After all this is your midterm evaluation. Cheating is something we can catch easily** ( we have also done this )"
      ],
      "metadata": {
        "id": "m5PHy4o-XSpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "[CLARIFICATION]: Reading and understanding by searching on Chatgpt is not \n",
        "considered as cheating as long as you are writing that in your own word\n",
        "( only problem is the crediblity of its information)\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "7AzClJq2Z8zI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Question: What is overfitting and underfitting below ( atleast 200 words )\n",
        "\n",
        "Answer: OVERFITTING:\n",
        "Overfitting is that case when model performs very well on training dataset but fails to generalize on unseen examples.It happens when\n",
        "model becomes to complex and it just focus more on memorizing training outputs for given input rather than gaining the underlying patterns.\n",
        "In overfitting we can see large difference between the losses and accuracies of validation and training data.In this model learns to fit the\n",
        "noise or any random variation on trainig dataset which cause ignorance of some features which can be in validation dataset that result in poor \n",
        "performance on validation or test datasets.Concisely,overfitting occurs due to following reasons:\n",
        "1.Model complexity:When a model is complex with large number of parameters or have large capcity can memorize training dataset.\n",
        "2.Lack of Training data:When the training dataset is small, the model may have limited exposure to diverse examples.Here model somehow fit the\n",
        "trainig dataset buut cant on validatin dataset.\n",
        "3.Lack of regularization:Overfitting will occurs when not enough use of regularization techniques,like L1 or L2 regularization,dropout or early stopping.\n",
        "4.Difference in data:overfitting occurs when training datasets are different from real world data that model is expected to encounter.\n",
        "The consequences of overfitting are high training accuracy and low validation or test accuracy. \n",
        "\n",
        "UNDERFITTING:\n",
        "Underfitting is that case for a model when it lack in catching underlyiing patterns and relationship ppresent inthe training data.\n",
        "It is basically seen when both validation and training accuracy are low,indicating that model is too simple or lacks the capacity to learn\n",
        "complex patterns and features.When a model is underfitted,it is unable to effectively generalize from the training data to implement on unseen\n",
        "datas.It means that the model's absorbing features are too less or can say less than required for capturing the intricacies of the data.\n",
        "Conclusively underfitting of model can arise due to following reason:\n",
        "1. Insufficient model capacity:It is when model is very simple,have less number of layers,features,units than required to handle complexity of \n",
        "the data. \n",
        "2.Limiting training data:This is when trainig dataset is too small or unable to represent whole feature for data,that is not enough data to learn\n",
        "meaningful relationships.\n",
        "3.Inapropriate features chosen: If important features are excluded or irrelevant features are included, the model may finds difficulty the relevant\n",
        " patterns and make accurate predictions.\n",
        " The consequences of underfitting are low training and validation accuracy.\n",
        "https://www.bing.com/search?q=overfitting&form=ANNTH1&refig=b743ed157f7d495c8836f44b7f727b8f\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aNTS7DqAWXVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Question: What are regularization techniques in machine learning?(200 words)\n",
        "\n",
        "Answer: Regularization techniques in machine learning are methods to prevent overfitting and increase the ability of model to generalize on new unseen dataset.The regularization \n",
        "technique creates additional constraints or penalities to the model during training,which reduce its overoptimization on the training data and promots more generalization.With help\n",
        "of regularization we can balance between fitting the training data well and prevent from overfitting.These are some commonly used regularization technique:\n",
        "1.L1 and L2 regularization(also known as Ridge and Lasso regression respectively):L1 regularization is used for feature selection and penality term(proportional to the absolute value of weights) \n",
        "is added to loss function so that it is more able to generalize and less error\n",
        "L1 regularization term = λ * Σ|w|\n",
        "cost function=  loss + λ * Σ|w|\n",
        "where λ is the is the regularization parameter that controls the strength of regularization.\n",
        "while L2 regularization adds penality term that is proportional to variance ,this envoke smaller weights\n",
        " and helps to have more even importance of each weights.\n",
        "L2 regularization term = λ1* Σ(w^2)\n",
        "cost function= Original loss + λ * Σ(w^2)\n",
        " λ1 is the regularization parameter,(w^2) denotes the squared value of each weight.\n",
        "λ and λ1 are very large parameters which give above cost function by approximation.\n",
        "\n",
        "https://www.analyticssteps.com/blogs/l2-and-l1-regularization-machine-learning\n",
        "https://www.geeksforgeeks.org/regularization-in-machine-learning/\n",
        "https://stackoverflow.com/questions/39052558/regularized-cost-function-with-very-large-%CE%BB\n",
        "\n",
        "2.Dropout:In this a randomly unit is dropped or inactive for training purpose,which helps network to more independent features.It helps in reducing interdependency of among neurons and \n",
        "reduce overfitting as it become trained to more distincts features.\n",
        "3.Data Augmentation:It involve different tranformation on training data which leads to same output so that model learns how to manipulate more quickly,this is the variety in the inputs \n",
        "which have same output.It reduces overfitting by introducing variety.\n",
        "4.Batch Normalization:It normalize the inputs of each layer in a neural network by adjusting its mean and variance to 0 and 1 respectively.\n",
        "5.Early stopping:It is basically monitering the validation dataset performance and when its accuracy start to degrade,training the model is stopped to avoid overfitting. \n",
        "\"\"\""
      ],
      "metadata": {
        "id": "TfDCiJG1X652"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Question: What dropout layer and what does it do?( read it from Tensorflow.org and write in 200 words)\n",
        "\n",
        "Answer: The dropout layer is a regularization technique used to prevent overfitting of a model.It enhance the capability of a model to generalize by randomly setting some of input units to 0 during the trainig phase.\n",
        "It cause noise or randomness in the network by dropping some portion of neuron or units in every trainig step. Through this the network of neuron prevented from too much dependent on specific units and encourages the network\n",
        "to learn more robust and generalizable features. By using dropout ,network of neuron become more resistant to overfitting.During training phase ,those randomly units number which are to be ignored are set as hyperparameter\n",
        "and it represent the probability of dropping out a unit.It can be possible that in different training iteration different units are dropped.When units are dropped out, their contributions to both the forward pass (activation)\n",
        " and the backward pass (gradient computation) are temporarily removed.\n",
        " The droput layer helps in preventing overfitting by coadaptation of neurons.It also encourages neurons to evenly dependent and less sensitive to individual units,leading to better performance.Dropout is a common regularization\n",
        "technique that is leveraged within the state of the art solutions to computer vision tasks such as pose estimation, object detection or semantic segmentation. The concept is simple to understand and easier to implement through\n",
        "its inclusion in many standard machine/deep learning libraries such as PyTorch, TensorFlow and Keras.\n",
        "\n",
        "https://www.baeldung.com/cs/ml-relu-dropout-layers\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "_VGMmK3XYEcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Question: What is L1 normalization? write its formulae as well( atleast 200 words )\n",
        "Answer:L1 normalization(also known as Least Absolute Deviations) is a technique used in machine learning to normalize the input vector or matrices(considered rows) by dividing with the sum of absolute values of its element that sum of magnitude is also known as l1 norm.\n",
        "By normalizing the sum of normalized elements of the vector can go upto 1 only not more than it.The motive of L1 normalization is to bring the vector or row of matrix to specific range and make it easy to compare with other\n",
        " vector or rows of matrix(different data) easy.By using L1 normalization in dataset,we can remove the efect of varying scale and magnitude,allows fairer comparisons and stable computations.If a vector have non-negative value\n",
        "of its component than by normalization it will not change its sign.L1 normalization can result in sparsity in the normalized vector,because if vector have elements close to zero or zero than normalized vector will have more \n",
        "lesser magnitude values for each element.Also L1 normalization technique do not change the number of entries of vector.If a element in vector is having 0 value then after L1 normalization its value will be 0.This normalization \n",
        "technique is commonly used as a feature scaling to bring features onto a similar scale.It should be consider while using this technique that it is applied carefully and suitability may vary accordingly to datasets.\n",
        "Its formula for a vector v is given by (L1_normal(v)):\n",
        "l1 norm=|v1|+|v2|+...+|vn|\n",
        "L1_normal(vi)= vi/(|v1|+|v2|+...+|vn|) \n",
        "∥v∥1=∑|vi|=1\n",
        "\n",
        "where vi represents the ith element of the vector v and n is the total number of elementsin v.\n",
        " If there is a matrix where each row represent vector than we us same formula for each row.\n",
        "\n",
        "https://stats.stackexchange.com/questions/502387/what-is-the-l1-normalization-of-some-data\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "xxRFxeCzYqir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Question: What is L2 normalization? write its formulae as well( atleast 200 words )\n",
        "\n",
        "Answer: L2 normalization (or Euclidean normalization) is a technique to normalize feature vectors or data instance in machine learning.Here scaling of each feature of vector is done by its L2 norm.\n",
        "The L2 norm of a vector is square root of sum of square of each feature of that vector.For a vector v=[v1,v2,....,vn],the l2 norm ||v||2 is given by:\n",
        "||x2||2=sqrt(x1^2 + x2^2 +....+xn^2)\n",
        "the formula for L2 normalization of a feature vectore x is as follows:\n",
        "L2_normalized(x)=x/||x||2\n",
        "To imply the L2 normalization on vector v,every features of vector is divided by its L2 norm.By this vector is being scaled to have a unit L2 norm,which means that distance  vector and origin equals 1.\n",
        "Use of L2 normalization as feature scaling technique to bring different features onto a similar scale.On dividing each feature by its L2norm ,the vector is scaled in that way so all features are of comparable \n",
        "magnitudes.This helps to prevent that feature which is dominating the learning process and ensure that all features contribute evenly to the model.L2 normalization transforms the vector into a unit vector also \n",
        "known as normal vector whose distance from origin is 1.Thi is very useful in distance-based algorithms,where direction and relative magnitude of the features are more important than its absolute values.\n",
        "L2 normalization is used as regularization technique to prevent overfitting.By using L2 norm of the weight vector as a penalty term to the loss function, the model is encouraged to have small weights, which\n",
        " helps reduce overfitting by reducing the complexity of the model.It should be noted that L2 normalization is also applied carefully as L1 normalization.\n",
        "\n",
        "https://stats.stackexchange.com/questions/331926/explain-meaning-and-purpose-of-l2-normalization\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Qdqqsw9iYyMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Question: What is data augmentation techniques and why is it needed in machine learning?( atleast 200 words )\n",
        "\n",
        "Answer:Data augmentation is the way to increase training dataset by using modification or various transformation in the copies of existing training datasets.It is use to train model with more variety of input cases\n",
        "possible for each output,helps model to recognize the  correct output for given input.It improves model's performance and generalization process of machine learning models also improve model robustness.Because\n",
        "of data augmentation number of sample data increases in training set.It also address the class imbalance,enhance model robustness,and promote noise tolerance.So by expansion of training dataset with transformation \n",
        "application ,model can learn more effectively and give efficient result on unseen dataset.Data augmentation in machine learning is needed in machine learning for several reasons as mentioned below:\n",
        "1.To expand training datase:In many machine learning tasks,having large and diverse training dataset is needed for training correctly and robust models.Since,acquiring a large numbered label dataset can be expansive\n",
        " and time consuming,data augmentation provides way to increase training dataset artificially.\n",
        "2.Generalizing ability: Data augmentation enhance the ability of model to generalize in better than without it.This reduces overfitting, where the model becomes too specialized to the training data and performs poorly \n",
        "on unseen data.\n",
        "3.Addressing class imbalance:In some model,it may be the case that some classes have significantly fewer examples than others.This can lead to biased output and perform poor on less dominated classes.By using data\n",
        " augmentation we can create more training input for minority classes.It allows the model to learn feom more balanced representation of classes.\n",
        "4.Invariance:by application of tranformation like aligment change,rotation, or other the model learns to recognize the features and patterns for all possible casses,which enables the model to better handle variations\n",
        " and distortions in the input data.\n",
        "5.Noise tolerance capacity:To inhance performance of model,capacity to tolerate noise is required in real world data.By using data augmentation we can generate corrupted data to train our model for such case input.\n",
        "some common data augmentation technioque are:Image Augmentation,Text Augmentation,Audio Augmentation,Augmentation in Time Series.\n",
        "\n",
        "https://www.tensorflow.org/tutorials/images/data_augmentation\n",
        "https://www.geeksforgeeks.org/python-data-augmentation/\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "E-U7uWKxY0yv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}