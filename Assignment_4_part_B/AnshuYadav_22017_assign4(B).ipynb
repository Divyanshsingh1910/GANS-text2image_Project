{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urgfiWQ29uRG"
      },
      "outputs": [],
      "source": [
        "!pip install visualkeras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import visualkeras\n",
        "from PIL import ImageFont\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-EBYRkzcmvV"
      },
      "source": [
        "### **Do not forget to connect to GPU runtime before training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7x_d1W4m-PRp"
      },
      "outputs": [],
      "source": [
        "#importing the dataset\n",
        "(X_train,Y_train),(X_test,Y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X_train,Y_train,test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFXXCof1Rbwf"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFbLM_wBDWRJ"
      },
      "outputs": [],
      "source": [
        "# Normalizing the values between -1 and 1\n",
        "\n",
        "X_train  = X_train/255\n",
        "X_test = X_test/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5cd4XTEBHtB"
      },
      "outputs": [],
      "source": [
        "# Create an ImageDataGenerator object with given augmentation settings(just an instance)\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=20,      # Random rotation within the range of [-20, 20] degrees\n",
        "    width_shift_range=0.1,  # Random horizontal shift within the range of [-0.1, 0.1] of the total width\n",
        "    height_shift_range=0.1, # Random vertical shift within the range of [-0.1, 0.1] of the total height\n",
        "    shear_range=0.2,        # Random shearing transformations within the range of [-0.2, 0.2]\n",
        "    zoom_range=0.2,         # Random zoom within the range of [0.8, 1.2]\n",
        "    horizontal_flip=True,   # Randomly flip inputs horizontally\n",
        "    fill_mode='nearest' ,    # Fill any newly created pixels with the nearest available pixel value\n",
        "    validation_split=0.2  # Split 20% of the data for validation\n",
        ")\n",
        "\n",
        "# Apply data augmentation to the training data\n",
        "augmented_images = datagen.flow(X_train, Y_train)\n",
        "\n",
        "# creating the validation data\n",
        "validation_data = datagen.flow(X_train, Y_train, subset='validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvBuEuh4c7V6"
      },
      "source": [
        "## **`This is an Open assignment with minimum instructions`**\n",
        "You are allowed to search all over the web--> find any articles or implement them--> try your experiments\n",
        "\n",
        "> **---> create the model**\\\n",
        "**---> tune the hyperparameters like learning_rate, filter/kernel size**\\\n",
        "**---> optimize the result**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9Bqkf61fGz4"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "You have got some experience form last assignment '\n",
        "Use that experience this time\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYfJtQTAdyLh"
      },
      "outputs": [],
      "source": [
        "#@title **IMPORTANT ANNOUNCEMENT**\n",
        "\"\"\"\n",
        "Now with this much freedom, you can do anything\n",
        "So make sure you understand what you do and after the end of this assignment\n",
        " you will have explain all the code you tried in a viva exam\n",
        " this will be the mid term evaluation.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dJ4qpyjek7L"
      },
      "source": [
        "## **YOUR EFFORTS WILL COUNT MORE THE RESULTS YOU GET**\n",
        "> **So make sure all the time you spent on this notebook should be visible from the notebook**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E92b0edzffZn"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Question: What is Batch Normalization? Why is it used for? How does it fix the\n",
        "problem it is used for? [ Answer in atleast 300 words]\n",
        "<cite your sources>\n",
        "\n",
        "Answer:\n",
        "\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch Normalization is an algorithmic method which increases the stability and training of neural networks faster.\n",
        "\n",
        "Using this, model converges to optimal solution at lesser epochs value then before.\n",
        "\n",
        "Basically, In this output/activation of each mini-batch are normalized (mean set to 0 and variance to 1).\n",
        "\n",
        "Uses of Batch normalization: It allows the use of higher learning rates during training. By which network converges more quickly.\n",
        "It reduces the dependency of the network on the initial parameter values and hyperparameters.\n",
        "\n",
        "By ensuring that the inputs to each layer have a standardized distribution, Batch Normalization stabilizes the gradient flow during backpropagation.\n",
        "\n",
        "Helps in reducing overfitting, also improve models generalizing capability.\n",
        "Fixing problem:\n",
        "\n",
        "Batch norm is applied with mini-batch gradient descent. It is applied layer by layer and also optional for each layer inputs. Let us see how it works: Suppose a mini-batch B of size m of training dataset. The empirical mean and variance for B can be denoted as to denote a mini-batch of size m of the entire training set. The empirical mean(μ) and variance(σ^2) of B could thus be denoted as μ = (1 / m) * Σ(xi)\n",
        "\n",
        "σ^2 = (1 / m) * Σ((xi - μ)^2) where xi are the activations for a particular layer of model.\n",
        "\n",
        "For a layer of the network with d-dimensional input, xi=(xi(1),...,x(d)), each dimension is then normalized (i.e. re-centered and re-scaled)separately,\n",
        "\n",
        "xi(k)normalized= (xi(k)-μ(k)/(σ(k)^2 + ε )^.5\n",
        "\n",
        "where k∈[1,d] and i∈[1,m] ;μ(k) and σ(k) are the mean and standard deviation respectively for each dimension.\n",
        "Here, ε is a small constant, typically it is to ensure that the denominator is non-zero and to avoid numerical complications, in case of zero variance.. After normalization, activations are scaled and shifted using learnable parameters γ (gamma) and β (beta). It allow the model to control and adjust the normalized values. The scaling and shifting operations enable the network to learn the optimal representation for each layer.\n",
        "\n",
        "Shifted activations = γ * xi(k) + β\n",
        "\n",
        "Also by adjusting the values of γ and β during training process, network leans to capture and represent the data more effectively."
      ],
      "metadata": {
        "id": "MRrTndmjFhsw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://en.wikipedia.org/wiki/Batch_normalization"
      ],
      "metadata": {
        "id": "_Kv4IqroENH4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://paperswithcode.com/method/batch-normalization"
      ],
      "metadata": {
        "id": "hAGmroNAEdSn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQppujL4gyZZ"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Tutorial: https://www.tensorflow.org/tutorials/images/classification\n",
        "\n",
        "Above tutorial does exactly the same job\n",
        "But I will zero marks for exact same model used in the tutorial\n",
        "\n",
        "You need experiment with different layers and all those\n",
        "experiments should be visible by your notebooks\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6NlKl-bB74H"
      },
      "outputs": [],
      "source": [
        "# model initialization\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Intermediate layers\n",
        "model.add(tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.Conv2D(16, (3,3), activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.Conv2D(16, (3,3), activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# final layer\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model.build(input_shape=(X_train.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5hokZZ1FaDI"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdIOuHAyEEUp"
      },
      "outputs": [],
      "source": [
        "#@title Visualization\n",
        "\n",
        "# just run this cell as it is\n",
        "tf.keras.utils.plot_model(model, to_file='cnn_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zllpup2ZEW1Q"
      },
      "outputs": [],
      "source": [
        "# just run this cell as it is\n",
        "visualkeras.layered_view(model, legend=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnEXCG4gEv4Z"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "In the last part of the assignment\n",
        "try experimenting with learning rate.\n",
        "May be decreasing the lr might had help?\n",
        "\"\"\"\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiNN6SYMFBgI"
      },
      "outputs": [],
      "source": [
        "# This is another way of dealing with the generated data\n",
        "# both X_train and Y_train are inside the augmented image\n",
        "\n",
        "history = model.fit(augmented_images, epochs=6,validation_data = validation_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9QQWplIFJUI"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'],label=\"Train accuracy\")\n",
        "plt.plot(history.history['val_accuracy'], label = \"Validation accuracy\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kZ4-pgwfZHn"
      },
      "outputs": [],
      "source": [
        "model.evaluate(X_test,Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4sAtMyYeWT9"
      },
      "source": [
        "## **TRY DIFFERENT MODELS AND COMPARE THE RESULTS**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#with changed kernel size (7,7)\n",
        "model2 = tf.keras.Sequential()\n",
        "#addition of dropoutlayer\n",
        "# Intermediate layers\n",
        "model2.add(tf.keras.layers.Conv2D(32, (7,7), activation='relu', input_shape=(32, 32, 3)))\n",
        "model2.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model2.add(tf.keras.layers.Conv2D(16, (3,3), activation='relu'))\n",
        "model2.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model2.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model2.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model2.add(tf.keras.layers.Dropout(0.05))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# final layer\n",
        "model2.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model2.build(input_shape=(X_train.shape))"
      ],
      "metadata": {
        "id": "IAFJgs8czK6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "metadata": {
        "id": "QwSuo8F23vk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model2, to_file='cnn_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "OnOl_l4z3wrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "_fWCBAql39_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model2.fit(augmented_images, epochs=5,validation_data = validation_data)"
      ],
      "metadata": {
        "id": "ddM2y4hQ4DEt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ba4d11-999f-4ff0-c67c-df2bc40b547d"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1094/1094 [==============================] - 68s 62ms/step - loss: 2.0026 - accuracy: 0.1155 - val_loss: 1.8080 - val_accuracy: 0.0726\n",
            "Epoch 2/5\n",
            "1094/1094 [==============================] - 54s 49ms/step - loss: 1.7581 - accuracy: 0.1085 - val_loss: 1.6947 - val_accuracy: 0.0966\n",
            "Epoch 3/5\n",
            "1094/1094 [==============================] - 55s 51ms/step - loss: 1.6817 - accuracy: 0.1011 - val_loss: 1.6287 - val_accuracy: 0.1253\n",
            "Epoch 4/5\n",
            "1094/1094 [==============================] - 55s 50ms/step - loss: 1.6363 - accuracy: 0.0995 - val_loss: 1.6134 - val_accuracy: 0.1120\n",
            "Epoch 5/5\n",
            "1094/1094 [==============================] - 54s 50ms/step - loss: 1.6088 - accuracy: 0.0979 - val_loss: 1.5782 - val_accuracy: 0.0857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'],label=\"Train accuracy\")\n",
        "plt.plot(history.history['val_accuracy'], label = \"Validation accuracy\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "G82sVQ8R4RJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "sQ5Y0QT74XaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#with changed kernel size (3,3)\n",
        "\n",
        "model3 = tf.keras.Sequential()\n",
        "\n",
        "# Intermediate layers\n",
        "model3.add(tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model3.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model3.add(tf.keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
        "model3.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model3.add(tf.keras.layers.Conv2D(12, (3,3), activation='relu'))\n",
        "model3.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "\n",
        "model3.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model3.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# final layer\n",
        "model3.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model3.build(input_shape=(X_train.shape))"
      ],
      "metadata": {
        "id": "F7QdauFN6mmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.summary()"
      ],
      "metadata": {
        "id": "UarziufI7fFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model3, to_file='cnn_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "PW_HIoKN7jEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.00003),\n",
        "                  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "9X7Hlb8P7nX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model3.fit(augmented_images, epochs=5,validation_data = validation_data)"
      ],
      "metadata": {
        "id": "2dEpfMIE701u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'],label=\"Train accuracy\")\n",
        "plt.plot(history.history['val_accuracy'], label = \"Validation accuracy\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "ip1KeBP48B5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "oPrhFHX68Etx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding dense layer\n",
        "model4 = tf.keras.Sequential()\n",
        "\n",
        "# Intermediate layers\n",
        "model4.add(tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model4.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "#model4.add(tf.keras.layers.Conv2D(16, (3,3), activation='relu'))\n",
        "#model4.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "#model4.add(tf.keras.layers.Conv2D(16, (3,3), activation='relu'))\n",
        "#model4.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model4.add(tf.keras.layers.Flatten())\n",
        "model4.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model4.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "\n",
        "model4.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# final layer\n",
        "model4.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model4.build(input_shape=(X_train.shape))"
      ],
      "metadata": {
        "id": "-yGU38UxEMi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4.summary()"
      ],
      "metadata": {
        "id": "PumYgeUpEWZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model4, to_file='cnn_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "VCK0quwaEsNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.00003),\n",
        "                  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ugw8PubfE85d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model4.fit(augmented_images, epochs=5,validation_data = validation_data)"
      ],
      "metadata": {
        "id": "-IJELClIFBRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'],label=\"Train accuracy\")\n",
        "plt.plot(history.history['val_accuracy'], label = \"Validation accuracy\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "0mB85dZcFFcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "7zvSmob0FIxx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}